{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T14:19:27.414594Z",
     "iopub.status.busy": "2025-07-16T14:19:27.414050Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gemini API configured successfully.\n",
      "\n",
      "======================================================================\n",
      "üßÆ Solving Problem: Find the derivative of the Weierstrass function, defined as f(x) = Œ£ [from n=0 to ‚àû] a‚Åø * cos(b‚ÅøœÄx), for 0 < a < 1 and ab > 1 + (3/2)œÄ.\n",
      "üéØ Expected Answer: The function is continuous everywhere but differentiable nowhere. Therefore, the derivative does not exist for any value of x.\n",
      "----------------------------------------------------------------------\n",
      "Step 1/5 (Attempt 1) | Action: identify_and_setup | Result: ‚ùå\n",
      "  üí¨ Learner: Identify the function as an infinite series of trigonometric functions.  The problem requires finding the derivative of a function defined by an infinite sum.  The key is to apply the term-by-term differentiation rule to the series, assuming the resulting series converges uniformly in a suitable interval.\n",
      "  üë®‚Äç‚öñÔ∏è Judge: INCORRECT: This approach is flawed because the series of derivatives for the Weierstrass function does not converge, meaning the assumption for term-by-term differentiation is not met and this method will not lead to the correct answer.\n",
      "Step 1/5 (Attempt 2) | Action: initial_decomposition | Result: ‚ùå\n",
      "  üí¨ Learner: The Weierstrass function is a sum of cosine functions.  To find its derivative, a direct application of the term-by-term differentiation rule for infinite series is not appropriate.  The series defining the function does not uniformly converge, and therefore, we cannot simply differentiate the terms and recombine.  This necessitates a different approach focusing on the properties of the function itself and possibly using a different method of differentiation, such as differentiating under the summation sign (which, given the feedback, is likely an incorrect approach).  Further analysis and understanding of the convergence properties of the Weierstrass function are required.\n",
      "  üë®‚Äç‚öñÔ∏è Judge: INCORRECT: The step incorrectly states that the series defining the function does not converge uniformly, when in fact it does converge uniformly by the Weierstrass M-test since a < 1.\n",
      "  ‚ö†Ô∏è Max retries reached for step 1. Accepting incorrect step.\n",
      "Step 2/5 (Attempt 1) | Action: select_technique | Result: ‚ùå\n",
      "  üí¨ Learner: Let $f(x) = \\sum_{n=0}^{\\infty} a^n \\cos(b^n \\pi x)$.\n",
      "\n",
      "We can write the $n$-th term as $f_n(x) = a^n \\cos(b^n \\pi x)$.  To find the derivative of $f_n(x)$, we apply the chain rule:\n",
      "\n",
      "$f_n'(x) = a^n \\cdot (-\\sin(b^n \\pi x)) \\cdot (b^n \\pi) = -a^n b^n \\pi \\sin(b^n \\pi x)$.\n",
      "\n",
      "Now, we consider the series $\\sum_{n=0}^{\\infty} f_n'(x) = \\sum_{n=0}^{\\infty} -a^n b^n \\pi \\sin(b^n \\pi x)$.\n",
      "  üë®‚Äç‚öñÔ∏è Judge: INCORRECT: The step implicitly assumes that the derivative of the sum is the sum of the derivatives, but this interchange of differentiation and summation is not valid for the Weierstrass function under the given conditions.\n",
      "Step 2/5 (Attempt 2) | Action: apply_core_rule | Result: ‚úÖ\n",
      "  üí¨ Learner: Let $f(x) = \\sum_{n=0}^{\\infty} a^n \\cos(b^n \\pi x)$.\n",
      "\n",
      "We need to investigate the convergence properties of the series in order to determine if term-by-term differentiation is permissible.\n",
      "\n",
      "Since $0 < a < 1$ and $ab > 1 + \\frac{3}{2}\\pi$, we know that the series converges pointwise for all $x \\in \\mathbb{R}$.  However, this pointwise convergence is not sufficient for interchanging differentiation and summation.  A more rigorous approach is needed to ensure uniform convergence on a specific interval.  We will utilize a result from analysis about the uniform convergence of a series of continuous functions.\n",
      "  üë®‚Äç‚öñÔ∏è Judge: CORRECT: The step accurately identifies the need to analyze the convergence of the series to justify term-by-term differentiation and correctly states that pointwise convergence is insufficient.\n",
      "Step 3/5 (Attempt 1) | Action: execute_calculation | Result: ‚ùå\n",
      "  üí¨ Learner: To find the derivative of $f(x) = \\sum_{n=0}^{\\infty} a^n \\cos(b^n \\pi x)$, we need to investigate the uniform convergence of the series of functions.  A standard approach is to apply the Weierstrass M-test.\n",
      "\n",
      "We have $|a^n \\cos(b^n \\pi x)| \\le |a^n|$.  Since $0 < a < 1$, the series $\\sum_{n=0}^{\\infty} |a^n|$ converges by the geometric series test.\n",
      "\n",
      "Thus, by the Weierstrass M-test, the series $\\sum_{n=0}^{\\infty} a^n \\cos(b^n \\pi x)$ converges uniformly on $\\mathbb{R}$.  This allows us to differentiate term-by-term.\n",
      "\n",
      "Differentiating each term in the sum:\n",
      "\n",
      "$\\frac{d}{dx} (a^n \\cos(b^n \\pi x)) = -a^n b^n \\pi \\sin(b^n \\pi x)$\n",
      "\n",
      "Therefore,  $f'(x) = \\sum_{n=0}^{\\infty} \\frac{d}{dx} (a^n \\cos(b^n \\pi x)) = \\sum_{n=0}^{\\infty} -a^n b^n \\pi \\sin(b^n \\pi x)$.\n",
      "  üë®‚Äç‚öñÔ∏è Judge: INCORRECT: The justification for term-by-term differentiation is invalid, as the uniform convergence of the original series is not sufficient; the series of the derivatives must also converge uniformly.\n",
      "Step 3/5 (Attempt 2) | Action: execute_calculation | Result: ‚úÖ\n",
      "  üí¨ Learner: To find the derivative of f(x), we need to investigate the convergence of the series of derivatives.  We have:\n",
      "\n",
      "f'(x) =  Œ£<sub>n=0</sub><sup>‚àû</sup> a<sup>n</sup> * (-b<sup>n</sup>œÄ) * sin(b<sup>n</sup>œÄx)\n",
      "\n",
      "Now we need to analyze the convergence of this new series.  Crucially, we need to examine if the series of derivatives converges uniformly on some interval.  Without a specific interval, we cannot definitively state whether this convergence holds.  The crucial component needed for uniform convergence is a bound on the derivatives that doesn't depend on x.\n",
      "  üë®‚Äç‚öñÔ∏è Judge: CORRECT: The step correctly identifies the series of derivatives and correctly states that its convergence must be investigated to determine the differentiability of the function.\n",
      "Step 4/5 (Attempt 1) | Action: check_for_edge_cases | Result: ‚ùå\n",
      "  üí¨ Learner: ```\n",
      "f'(x) = Œ£<sub>n=0</sub><sup>‚àû</sup> a<sup>n</sup> * (-b<sup>n</sup>œÄ) * sin(b<sup>n</sup>œÄx)\n",
      "\n",
      "```\n",
      "\n",
      "No intermediate errors are apparent.  The expression is already simplified as much as possible.  The expression is a series of the form  Œ£<sub>n=0</sub><sup>‚àû</sup> c<sub>n</sub> * sin(d<sub>n</sub>x), where c<sub>n</sub> = -a<sup>n</sup>b<sup>n</sup>œÄ and d<sub>n</sub> = b<sup>n</sup>œÄ.  The terms are well-defined.\n",
      "\n",
      "\n",
      "No obvious edge cases are present that would invalidate the expression.  The form is standard.  Further analysis is needed to determine the region of uniform convergence of this new series.  Crucially, the conditions given about a and b (0 < a < 1 and ab > 1 + (3/2)œÄ) are critical and must be used in any further analysis of convergence.  This is not yet a sufficient condition for uniform convergence, but it is a necessary condition to establish the existence of the derivative.\n",
      "  üë®‚Äç‚öñÔ∏è Judge: INCORRECT: This step incorrectly assumes that the derivative of the sum is the sum of the derivatives, which is not valid because the resulting series of derivatives diverges under the given conditions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "import google.generativeai as genai\n",
    "\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    api_key = user_secrets.get_secret(\"GEMINI_API_KEY\")\n",
    "    genai.configure(api_key=api_key)\n",
    "    # The print statement is optional, but helpful for debugging\n",
    "    # print(\"‚úÖ Successfully configured Gemini API from Kaggle Secrets.\") \n",
    "except Exception as e:\n",
    "    # This will run if the secret is not found, e.g., you forgot to add it.\n",
    "    print(f\"‚ö†Ô∏è Could not configure Gemini API. Please ensure you have added your key to Kaggle Secrets with the label 'GEMINI_API_KEY'. Error: {e}\")\n",
    "\n",
    "@dataclass\n",
    "class MathProblem:\n",
    "    problem: str\n",
    "    problem_type: str\n",
    "    difficulty: str\n",
    "    expected_answer: str\n",
    "\n",
    "@dataclass\n",
    "class StepResult:\n",
    "    step_number: int\n",
    "    action: str\n",
    "    step_content: str\n",
    "    is_correct: bool\n",
    "    reward: float\n",
    "    judge_feedback: str = \"\"\n",
    "    attempts: int = 1\n",
    "\n",
    "class QLearningAgent:\n",
    "    \"\"\"\n",
    "    Implements the Q-learning algorithm exactly as specified in the image.\n",
    "    Q(S, A) <- Q(S, A) + Œ± * [R + Œ≥ * max_a Q(S', a) - Q(S, A)]\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate=0.1, discount_factor=0.9, epsilon=0.2):\n",
    "        self.learning_rate: float = learning_rate\n",
    "        self.discount_factor: float = discount_factor\n",
    "        self.epsilon: float = epsilon\n",
    "        self.q_table: Dict[str, Dict[str, float]] = defaultdict(lambda: defaultdict(float))\n",
    "        # A more structured action space for 5 steps\n",
    "        self.action_space: Dict[int, List[str]] = {\n",
    "            1: [\"identify_and_setup\", \"initial_decomposition\"],\n",
    "            2: [\"apply_core_rule\", \"select_technique\"],\n",
    "            3: [\"execute_calculation\", \"algebraic_manipulation\"],\n",
    "            4: [\"simplify_result\", \"check_for_edge_cases\"],\n",
    "            5: [\"final_answer_and_conclusion\", \"verify_solution\"]\n",
    "        }\n",
    "\n",
    "    def get_state(self, problem: MathProblem, step: int) -> str:\n",
    "        \"\"\"Create a simplified but effective state representation.\"\"\"\n",
    "        # State depends on problem type, difficulty, and current step number.\n",
    "        return f\"{problem.problem_type}_{problem.difficulty}_step{step}\"\n",
    "\n",
    "    def choose_action(self, state: str, step: int) -> str:\n",
    "        \"\"\"Choose action using epsilon-greedy policy from the available actions for the current step.\"\"\"\n",
    "        available_actions = self.action_space.get(step)\n",
    "        \n",
    "        # Exploration: choose a random action\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.choice(available_actions)\n",
    "        \n",
    "        # Exploitation: choose the best-known action\n",
    "        q_values_for_state = self.q_table[state]\n",
    "        \n",
    "        # Filter Q-values to only include actions available at this step\n",
    "        available_q_values = {action: q_values_for_state[action] for action in available_actions}\n",
    "        \n",
    "        if not available_q_values or all(v == 0 for v in available_q_values.values()):\n",
    "            # If no q-values learned yet for this state, choose randomly\n",
    "            return random.choice(available_actions)\n",
    "        \n",
    "        return max(available_q_values, key=available_q_values.get)\n",
    "\n",
    "    def update_q_value(self, state: str, action: str, reward: float, next_state: str, next_step: int):\n",
    "        \"\"\"\n",
    "        Update Q-value using the Bellman equation from the image.\n",
    "        Q(S, A) <- Q(S, A) + Œ± * [R + Œ≥ * max_a Q(S', a) - Q(S, A)]\n",
    "        \"\"\"\n",
    "        # 1. Get the old Q-value: Q(S, A)\n",
    "        current_q = self.q_table[state][action]\n",
    "\n",
    "        # 2. Find the maximum Q-value for the next state: max_a Q(S', a)\n",
    "        next_q_values = self.q_table[next_state]\n",
    "        available_next_actions = self.action_space.get(next_step, [])\n",
    "        \n",
    "        max_next_q = 0\n",
    "        if next_q_values and available_next_actions:\n",
    "            # Consider only actions available in the next step\n",
    "            relevant_next_q = [next_q_values[act] for act in available_next_actions]\n",
    "            if relevant_next_q:\n",
    "                max_next_q = max(relevant_next_q)\n",
    "        \n",
    "        # 3. Calculate the TD target: R + Œ≥ * max_a Q(S', a)\n",
    "        td_target = reward + self.discount_factor * max_next_q\n",
    "        \n",
    "        # 4. Calculate the TD error: td_target - Q(S, A)\n",
    "        td_error = td_target - current_q\n",
    "\n",
    "        # 5. Update the Q-value: Q(S, A) + Œ± * TD_error\n",
    "        new_q = current_q + self.learning_rate * td_error\n",
    "        self.q_table[state][action] = new_q\n",
    "        \n",
    "        # print(f\"  üß† Q-Update: s={state}, a={action}, r={reward:.1f} | OldQ:{current_q:.2f} -> NewQ:{new_q:.2f}\")\n",
    "\n",
    "class GeminiMathSolver:\n",
    "    def __init__(self, learner_model_name=\"gemini-1.5-flash-8b\", judge_model_name=\"gemini-2.5-pro\"):\n",
    "        self.agent = QLearningAgent()\n",
    "        self.max_steps = 5\n",
    "        self.max_retries_per_step = 2 # Allow the learner to try again if it makes a mistake\n",
    "        self.api_configured = False\n",
    "        \n",
    "        try:\n",
    "            self.learner_model = genai.GenerativeModel(learner_model_name)\n",
    "            self.judge_model = genai.GenerativeModel(judge_model_name)\n",
    "            self.api_configured = True\n",
    "            print(\"‚úÖ Gemini API configured successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Gemini API not configured. Running in MOCK mode. Error: {str(e)}\")\n",
    "    \n",
    "    def get_learner_response(self, problem: MathProblem, step: int, action: str, previous_steps: List[str], feedback: Optional[str] = None) -> str:\n",
    "        \"\"\"Generates a response from the learner model, incorporating feedback if provided.\"\"\"\n",
    "        if not self.api_configured:\n",
    "            return f\"[MOCK] Step {step}: Executing action '{action}' for problem type {problem.problem_type}.\"\n",
    "    \n",
    "        feedback_prompt = \"\"\n",
    "        if feedback:\n",
    "            feedback_prompt = f\"\"\"\n",
    "            Your previous attempt at this step was incorrect. Here is the feedback from the expert judge:\n",
    "            ---\n",
    "            {feedback}\n",
    "            ---\n",
    "            Please correct your mistake and provide a new, accurate response for this step.\n",
    "            \"\"\"\n",
    "    \n",
    "        # --- FIX IS HERE ---\n",
    "        # 1. Pre-format the 'previous_steps' string. Note the single backslash \\n is fine here.\n",
    "        if previous_steps:\n",
    "            previous_steps_str = \"\".join(f\"Step {i+1}: {s}\\n\" for i, s in enumerate(previous_steps))\n",
    "\n",
    "        else:\n",
    "            previous_steps_str = \"None\"\n",
    "        # --- END FIX ---\n",
    "    \n",
    "        step_instructions = {\n",
    "            1: \"Start by identifying the function/problem type and outlining the initial setup or first principle to apply.\",\n",
    "            2: \"Apply the main mathematical rule or technique (e.g., chain rule, integration by parts, matrix inversion).\",\n",
    "            3: \"Perform the necessary calculations and algebraic manipulations based on the previous step.\",\n",
    "            4: \"Simplify the resulting expression and check for any intermediate errors or edge cases.\",\n",
    "            5: \"State the complete, final answer clearly. This is your last step.\"\n",
    "        }\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "    You are an expert mathematician solving a calculus problem in a structured, 5-step process.\n",
    "    You are on step {step} of 5.\n",
    "    \n",
    "    Problem: {problem.problem}\n",
    "    \n",
    "    Previous Steps:\n",
    "    {previous_steps_str}\n",
    "    \n",
    "    Current Step Instructions ({step}/5): {step_instructions[step]}\n",
    "    Your high-level action for this step is: '{action}'.\n",
    "    \n",
    "    {feedback_prompt}\n",
    "    \n",
    "    Provide only the mathematical work for this current step.\n",
    "    {'This is the final step, you must provide the final answer.' if step == 5 else f'You have {5-step} steps remaining after this.'}\n",
    "    \"\"\"\n",
    "        response = self.learner_model.generate_content(prompt)\n",
    "        return response.text\n",
    "\n",
    "    def get_judge_evaluation(self, problem: MathProblem, step_content: str, step_number: int) -> Tuple[bool, float, str]:\n",
    "        \"\"\"Evaluates a step using the powerful judge model.\"\"\"\n",
    "        if not self.api_configured:\n",
    "            # Mock evaluation for testing without an API key\n",
    "            is_correct = random.random() > 0.4 # 60% chance of being correct\n",
    "            reward = (10 if is_correct else -5)\n",
    "            feedback = \"MOCK: This is a mock evaluation.\"\n",
    "            return is_correct, reward, feedback\n",
    "            \n",
    "        is_final_step = (step_number == self.max_steps)\n",
    "        \n",
    "        # --- CORRECTED JUDGE PROMPT ---\n",
    "        prompt = f\"\"\"\n",
    "    You are an expert mathematician and judge. Your task is to evaluate one step of a solution to a math problem.\n",
    "    The problem is: \"{problem.problem}\"\n",
    "    The expected final answer is: \"{problem.expected_answer}\"\n",
    "    \n",
    "    The current step being evaluated is Step {step_number}.\n",
    "    The student's submission for this step is:\n",
    "    ---\n",
    "    {step_content}\n",
    "    ---\n",
    "    \n",
    "    Based on the problem, the student's submission for this step, and the expected final answer, is this step correct?\n",
    "    - A step is CORRECT if it is mathematically sound and makes logical progress towards the final answer.\n",
    "    - A step is INCORRECT if it contains a mathematical error, a logical flaw, or is a step that doesn't lead to the correct solution.\n",
    "    \n",
    "    Start your response with the word \"CORRECT\" or \"INCORRECT\".\n",
    "    Then, provide a brief, one-sentence explanation for your decision.\n",
    "    \n",
    "    Example 1:\n",
    "    CORRECT: The application of the product rule is accurate.\n",
    "    \n",
    "    Example 2:\n",
    "    INCORRECT: The derivative of sin(x) is -cos(x), not cos(x) as written.\n",
    "    \n",
    "    Example 3:\n",
    "    INCORRECT: The calculation is correct, but this approach of integration by parts will not lead to the final answer.\n",
    "    \n",
    "    Now, evaluate the student's submission. The final answer should be: {problem.expected_answer}\n",
    "    \"\"\"\n",
    "        # --- END CORRECTED JUDGE PROMPT ---\n",
    "        \n",
    "        try:\n",
    "            response = self.judge_model.generate_content(prompt)\n",
    "            feedback_text = response.text.strip()\n",
    "            \n",
    "            is_correct = feedback_text.upper().startswith('CORRECT')\n",
    "            \n",
    "            # Define rewards\n",
    "            if is_correct:\n",
    "                reward = 15.0 if is_final_step else 5.0 + step_number\n",
    "            else:\n",
    "                reward = -20.0 if is_final_step else -10.0\n",
    "                \n",
    "            return is_correct, reward, feedback_text\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error during judge evaluation: {str(e)}\")\n",
    "            return False, -15.0, f\"Evaluation failed due to an API error: {e}\"\n",
    "\n",
    "    def solve_problem(self, problem: MathProblem) -> List[StepResult]:\n",
    "        \"\"\"Solves a problem using the Q-learning guided, 5-step process with retries.\"\"\"\n",
    "        print(f\"\\n\" + \"=\"*70)\n",
    "        print(f\"üßÆ Solving Problem: {problem.problem}\")\n",
    "        print(f\"üéØ Expected Answer: {problem.expected_answer}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        results = []\n",
    "        previous_steps_content = []\n",
    "\n",
    "        for step in range(1, self.max_steps + 1):\n",
    "            state = self.agent.get_state(problem, step)\n",
    "            feedback_for_retry = None\n",
    "            \n",
    "            for attempt in range(1, self.max_retries_per_step + 1):\n",
    "                # 1. Choose Action A from State S\n",
    "                action = self.agent.choose_action(state, step)\n",
    "\n",
    "                # 2. Take Action A, get Step Content\n",
    "                step_content = self.get_learner_response(problem, step, action, previous_steps_content, feedback_for_retry)\n",
    "                \n",
    "                # 3. Observe Reward R and Next State S'\n",
    "                is_correct, reward, judge_feedback = self.get_judge_evaluation(problem, step_content, step)\n",
    "                \n",
    "                status_icon = \"‚úÖ\" if is_correct else \"‚ùå\"\n",
    "                print(f\"Step {step}/{self.max_steps} (Attempt {attempt}) | Action: {action} | Result: {status_icon}\")\n",
    "                print(f\"  üí¨ Learner: {step_content.strip()}\")\n",
    "                print(f\"  üë®‚Äç‚öñÔ∏è Judge: {judge_feedback.strip()}\")\n",
    "                \n",
    "                if is_correct:\n",
    "                    # The step was correct, finalize and move to the next step\n",
    "                    result = StepResult(step, action, step_content, is_correct, reward, judge_feedback, attempt)\n",
    "                    results.append(result)\n",
    "                    previous_steps_content.append(step_content)\n",
    "                    \n",
    "                    # 4. Update Q-Table\n",
    "                    next_step = step + 1\n",
    "                    next_state = self.agent.get_state(problem, next_step) if next_step <= self.max_steps else \"terminal\"\n",
    "                    self.agent.update_q_value(state, action, reward, next_state, next_step)\n",
    "                    \n",
    "                    time.sleep(1) # API rate limiting\n",
    "                    break # Exit the retry loop\n",
    "                else:\n",
    "                    # The step was incorrect, prepare for another attempt\n",
    "                    feedback_for_retry = judge_feedback\n",
    "                    # Apply a penalty for the failed attempt and update Q-value to discourage this action\n",
    "                    self.agent.update_q_value(state, action, reward, state, step) # Update with penalty, next_state is current state\n",
    "                    \n",
    "                    if attempt == self.max_retries_per_step:\n",
    "                        # Max retries reached, accept the wrong answer and move on\n",
    "                        print(f\"  ‚ö†Ô∏è Max retries reached for step {step}. Accepting incorrect step.\")\n",
    "                        result = StepResult(step, action, step_content, is_correct, reward, judge_feedback, attempt)\n",
    "                        results.append(result)\n",
    "                        previous_steps_content.append(step_content)\n",
    "                        break # Exit the retry loop\n",
    "                    \n",
    "                    time.sleep(1) # API rate limiting\n",
    "\n",
    "        # Final Summary\n",
    "        total_reward = sum(r.reward for r in results)\n",
    "        correct_steps = sum(1 for r in results if r.is_correct)\n",
    "        print(\"\\n\" + \"-\"*30 + \" SUMMARY \" + \"-\"*30)\n",
    "        print(f\"üìä Final Result: {correct_steps}/{self.max_steps} steps correct.\")\n",
    "        print(f\"üèÜ Total Reward: {total_reward:.1f}\")\n",
    "        print(\"=\"*70)\n",
    "        return results\n",
    "\n",
    "# --- Main Execution ---\n",
    "def create_hard_problems() -> List[MathProblem]:\n",
    "    \"\"\"Create a list of hard and very hard sample math problems for testing.\"\"\"\n",
    "    return [\n",
    "        MathProblem(\n",
    "            problem=\"Find the derivative of the Weierstrass function, defined as f(x) = Œ£ [from n=0 to ‚àû] a‚Åø * cos(b‚ÅøœÄx), for 0 < a < 1 and ab > 1 + (3/2)œÄ.\",\n",
    "            problem_type=\"derivative\",\n",
    "            difficulty=\"very_hard\",\n",
    "            expected_answer=\"The function is continuous everywhere but differentiable nowhere. Therefore, the derivative does not exist for any value of x.\"\n",
    "        ),\n",
    "        MathProblem(\n",
    "            problem=\"Consider f_n(x) = 2nx*e^(-nx¬≤) on [0, 1]. Evaluate lim[n‚Üí‚àû] ‚à´[0 to 1] f_n(x) dx and ‚à´[0 to 1] lim[n‚Üí‚àû] f_n(x) dx. Are they equal?\",\n",
    "            problem_type=\"real_analysis\",\n",
    "            difficulty=\"very_hard\",\n",
    "            expected_answer=\"They are not equal. The integral of the limit is ‚à´0 dx = 0. The limit of the integral is lim[n‚Üí‚àû] (1 - e‚Åª‚Åø) = 1. They differ because convergence is not uniform, so the limit and integral cannot be interchanged.\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "\n",
    "def main():\n",
    "    solver = GeminiMathSolver()\n",
    "    if not solver.api_configured:\n",
    "        print(\"\\n--- RUNNING IN MOCK MODE. NO REAL LEARNING WILL OCCUR. ---\")\n",
    "        print(\"--- Please configure your Gemini API key to run properly. ---\")\n",
    "\n",
    "    problems = create_hard_problems()\n",
    "    for prob in problems:\n",
    "        solver.solve_problem(prob)\n",
    "\n",
    "    print(\"\\n\\n\" + \"=\"*30 + \" FINAL Q-TABLE STATE \" + \"=\"*30)\n",
    "    # Print a few learned Q-values to show it's working\n",
    "    if solver.agent.q_table:\n",
    "        for i, (state, actions) in enumerate(solver.agent.q_table.items()):\n",
    "            if i >= 5: break\n",
    "            print(f\"State: {state}\")\n",
    "            for action, value in actions.items():\n",
    "                print(f\"  - Action: {action}, Q-Value: {value:.3f}\")\n",
    "    else:\n",
    "        print(\"Q-Table is empty (likely ran in mock mode).\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Section 2 (this Section test by saving Q-table)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T14:05:31.812602Z",
     "iopub.status.busy": "2025-07-16T14:05:31.811943Z",
     "iopub.status.idle": "2025-07-16T14:09:18.248602Z",
     "shell.execute_reply": "2025-07-16T14:09:18.247595Z",
     "shell.execute_reply.started": "2025-07-16T14:05:31.812577Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ No existing model found at math_qlearning_model.json. Starting with empty Q-table.\n",
      "‚úÖ Gemini API configured successfully.\n",
      "\n",
      "============================== MODEL STATISTICS ==============================\n",
      "üìä Total States: 0\n",
      "üìä Total State-Action Pairs: 0\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üßÆ Solving Problem: Find the derivative of the Weierstrass function, defined as f(x) = Œ£ [from n=0 to ‚àû] a‚Åø * cos(b‚ÅøœÄx), for 0 < a < 1 and ab > 1 + (3/2)œÄ.\n",
      "üéØ Expected Answer: The function is continuous everywhere but differentiable nowhere. Therefore, the derivative does not exist for any value of x.\n",
      "----------------------------------------------------------------------\n",
      "Step 1/5 (Attempt 1) | Action: identify_and_setup | Result: ‚ùå\n",
      "  üí¨ Learner: **Step 1: Identify and Setup**\n",
      "\n",
      "The problem is to find the derivative of a function defined by an infinite series.  The function f(x) = Œ£ [from n=0 to ‚àû] a‚Åø * cos(b‚ÅøœÄx)  is a trigonometric series.  To find the derivative, we will employ the term-by-term differentiation rule, which states that if a function is defined by a convergent power series, the derivative of the function can be obtained by differentiating each term of the series, provided the resulting series converges.  This will require establishing the convergence properties of the differentiated series.\n",
      "  üë®‚Äç‚öñÔ∏è Judge: INCORRECT: The stated goal is to find the derivative, which is a flawed premise because the correct conclusion is that the derivative does not exist.\n",
      "Step 1/5 (Attempt 2) | Action: initial_decomposition | Result: ‚úÖ\n",
      "  üí¨ Learner: The Weierstrass function is a sum of cosine functions.  To find its derivative, we must analyze the differentiability of the individual terms and the convergence properties of the resulting series.  The key here is to understand that the convergence of the original series does *not* guarantee the convergence of the series obtained by term-by-term differentiation.  We will attempt to apply the term-by-term differentiation rule, recognizing the potential for divergence, and focusing on the conditions that will lead to failure.\n",
      "  üë®‚Äç‚öñÔ∏è Judge: CORRECT: The student correctly identifies the core issue of the problem, which is that term-by-term differentiation is not guaranteed to work and that its failure is the key to proving the function is nowhere differentiable.\n",
      "Step 2/5 (Attempt 1) | Action: select_technique | Result: ‚ùå\n",
      "  üí¨ Learner: Applying the term-by-term differentiation rule, we find the derivative of each cosine term:\n",
      "\n",
      "d/dx [a‚Åø cos(b‚ÅøœÄx)] = -a‚Åøb‚ÅøœÄ sin(b‚ÅøœÄx)\n",
      "  üë®‚Äç‚öñÔ∏è Judge: INCORRECT: The term-by-term differentiation rule cannot be applied because the conditions for its use, namely the uniform convergence of the series of derivatives, are not met for this function.\n",
      "Step 2/5 (Attempt 2) | Action: apply_core_rule | Result: ‚úÖ\n",
      "  üí¨ Learner: Let  g_n(x) = a^n * cos(b^n œÄx).  Then f(x) = Œ£ [from n=0 to ‚àû] g_n(x).\n",
      "\n",
      "The derivative of g_n(x) is  g'_n(x) = -a^n * b^n œÄ * sin(b^n œÄx).\n",
      "\n",
      "The series Œ£ [from n=0 to ‚àû] g'_n(x) represents the potential derivative of f(x).\n",
      "  üë®‚Äç‚öñÔ∏è Judge: CORRECT: The calculation of the derivative of the general term g_n(x) is accurate, and identifying the resulting series as the \"potential\" derivative is a valid and logical step toward proving the function is nowhere differentiable.\n",
      "Step 3/5 (Attempt 1) | Action: execute_calculation | Result: ‚úÖ\n",
      "  üí¨ Learner: Œ£ (from n=0 to ‚àû) g'_n(x) = Œ£ (from n=0 to ‚àû) -a^n * b^n œÄ * sin(b^n œÄx)\n",
      "  üë®‚Äç‚öñÔ∏è Judge: CORRECT: The derivative of each term in the series is calculated correctly using the chain rule.\n",
      "Step 4/5 (Attempt 1) | Action: simplify_result | Result: ‚ùå\n",
      "  üí¨ Learner: Œ£ (from n=0 to ‚àû) -a^n * b^n œÄ * sin(b^n œÄx) =  -œÄ Œ£ (from n=0 to ‚àû) (ab)^n * b^n  * sin(b^n œÄx)\n",
      "  üë®‚Äç‚öñÔ∏è Judge: INCORRECT: The algebraic manipulation is flawed, as `a^n * b^n` is not equal to `(ab)^n * b^n`.\n",
      "Step 4/5 (Attempt 2) | Action: check_for_edge_cases | Result: ‚ùå\n",
      "  üí¨ Learner: Œ£ (from n=0 to ‚àû) -a^n * b^n œÄ * sin(b^n œÄx) = -œÄ Œ£ (from n=0 to ‚àû) (a*b)^n * sin(b^n œÄx)\n",
      "  üë®‚Äç‚öñÔ∏è Judge: INCORRECT: This step performs term-by-term differentiation, but the conditions for this operation are not met, as the resulting series of derivatives does not converge.\n",
      "Step 4/5 (Attempt 3) | Action: simplify_result | Result: ‚ùå\n",
      "  üí¨ Learner: Œ£ (from n=0 to ‚àû) -a^n * b^n œÄ * sin(b^n œÄx)\n",
      "  üë®‚Äç‚öñÔ∏è Judge: INCORRECT: This step incorrectly assumes that the derivative of the sum is the sum of the derivatives, which is not valid for this function as the resulting series of derivatives does not converge.\n",
      "  ‚ö†Ô∏è Max retries reached for step 4. Accepting incorrect step.\n",
      "Step 5/5 (Attempt 1) | Action: verify_solution | Result: ‚ùå\n",
      "  üí¨ Learner: The series Œ£ [from n=0 to ‚àû] -a^n * b^n œÄ * sin(b^n œÄx) converges uniformly by the Weierstrass M-test.  This is where the condition ab > 1 + (3/2)œÄ comes into play.  A suitable dominating function for the absolute value of the terms is M_n = |a^n * b^n * œÄ| = |a^n * b^n œÄ|, which is a geometric series with common ratio ab.  Since 0 < a < 1 and ab > 1 + (3/2)œÄ, the geometric series converges.\n",
      "\n",
      "Therefore, the derivative of the Weierstrass function is:\n",
      "\n",
      "f'(x) =  -œÄ * Œ£ [from n=0 to ‚àû] a‚Åø b‚Åø sin(b‚ÅøœÄx)\n",
      "  üë®‚Äç‚öñÔ∏è Judge: INCORRECT: The student claims that the geometric series with common ratio `ab` converges, but the given condition `ab > 1 + (3/2)œÄ` implies `ab > 1`, for which a geometric series diverges.\n",
      "Step 5/5 (Attempt 2) | Action: final_answer_and_conclusion | Result: ‚ùå\n",
      "  üí¨ Learner: The series Œ£ (from n=0 to ‚àû) -a^n * b^n œÄ * sin(b^n œÄx)  does not converge uniformly.  Therefore, the derivative of the Weierstrass function  f(x) = Œ£ [from n=0 to ‚àû] a‚Åø * cos(b‚ÅøœÄx)  cannot be found by term-by-term differentiation.\n",
      "\n",
      "**Final Answer:** The derivative does not exist.\n",
      "  üë®‚Äç‚öñÔ∏è Judge: INCORRECT: The conclusion that the derivative does not exist because term-by-term differentiation fails is a logical fallacy; the failure of one method does not prove non-existence.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36/2378903347.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_36/2378903347.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0mproblems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_hard_problems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproblems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m         \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve_problem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;31m# Print final model statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_36/2378903347.py\u001b[0m in \u001b[0;36msolve_problem\u001b[0;34m(self, problem)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;31m# 3. Observe Reward R and Next State S'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                 \u001b[0mis_correct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjudge_feedback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_judge_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0mstatus_icon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"‚úÖ\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_correct\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"‚ùå\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_36/2378903347.py\u001b[0m in \u001b[0;36mget_judge_evaluation\u001b[0;34m(self, problem, step_content, step_number)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjudge_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m             \u001b[0mfeedback_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 response = self._client.generate_content(\n\u001b[0m\u001b[1;32m    332\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mrequest_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    836\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             )\n\u001b[0;32m--> 349\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    350\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_since_first_attempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompression\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     ) -> Any:\n\u001b[0;32m--> 277\u001b[0;31m         response, ignored_call = self._with_call(\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m_with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_FailureOutcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         call = self._interceptor.intercept_unary_unary(\n\u001b[0m\u001b[1;32m    330\u001b[0m             \u001b[0mcontinuation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_call_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py\u001b[0m in \u001b[0;36mintercept_unary_unary\u001b[0;34m(self, continuation, client_call_details, request)\u001b[0m\n\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontinuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_call_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogging_enabled\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: NO COVER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mresponse_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrailing_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36mcontinuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    313\u001b[0m             ) = _unwrap_client_call_details(new_details, client_call_details)\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                 response, call = self._thunk(new_method).with_call(\n\u001b[0m\u001b[1;32m    316\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36mwith_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1193\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m             \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_for_ready\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registered_call_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m             )\n\u001b[0;32m-> 1162\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m             \u001b[0m_handle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "import google.generativeai as genai\n",
    "\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    api_key = user_secrets.get_secret(\"GEMINI_API_KEY\")\n",
    "    genai.configure(api_key=api_key)\n",
    "    # The print statement is optional, but helpful for debugging\n",
    "    # print(\"‚úÖ Successfully configured Gemini API from Kaggle Secrets.\") \n",
    "except Exception as e:\n",
    "    # This will run if the secret is not found, e.g., you forgot to add it.\n",
    "    print(f\"‚ö†Ô∏è Could not configure Gemini API. Please ensure you have added your key to Kaggle Secrets with the label 'GEMINI_API_KEY'. Error: {e}\")\n",
    "\n",
    "@dataclass\n",
    "class MathProblem:\n",
    "    problem: str\n",
    "    problem_type: str\n",
    "    difficulty: str\n",
    "    expected_answer: str\n",
    "\n",
    "@dataclass\n",
    "class StepResult:\n",
    "    step_number: int\n",
    "    action: str\n",
    "    step_content: str\n",
    "    is_correct: bool\n",
    "    reward: float\n",
    "    judge_feedback: str = \"\"\n",
    "    attempts: int = 1\n",
    "\n",
    "class QLearningAgent:\n",
    "    \"\"\"\n",
    "    Implements the Q-learning algorithm exactly as specified in the image.\n",
    "    Q(S, A) <- Q(S, A) + Œ± * [R + Œ≥ * max_a Q(S', a) - Q(S, A)]\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate=0.1, discount_factor=0.9, epsilon=0.2, model_path=\"qlearning_model.json\"):\n",
    "        self.learning_rate: float = learning_rate\n",
    "        self.discount_factor: float = discount_factor\n",
    "        self.epsilon: float = epsilon\n",
    "        self.model_path: str = model_path\n",
    "        self.q_table: Dict[str, Dict[str, float]] = defaultdict(lambda: defaultdict(float))\n",
    "        # A more structured action space for 5 steps\n",
    "        self.action_space: Dict[int, List[str]] = {\n",
    "            1: [\"identify_and_setup\", \"initial_decomposition\"],\n",
    "            2: [\"apply_core_rule\", \"select_technique\"],\n",
    "            3: [\"execute_calculation\", \"algebraic_manipulation\"],\n",
    "            4: [\"simplify_result\", \"check_for_edge_cases\"],\n",
    "            5: [\"final_answer_and_conclusion\", \"verify_solution\"]\n",
    "        }\n",
    "        \n",
    "        # Try to load existing model\n",
    "        self.load_model()\n",
    "\n",
    "    def get_state(self, problem: MathProblem, step: int) -> str:\n",
    "        \"\"\"Create a simplified but effective state representation.\"\"\"\n",
    "        # State depends on problem type, difficulty, and current step number.\n",
    "        return f\"{problem.problem_type}_{problem.difficulty}_step{step}\"\n",
    "\n",
    "    def choose_action(self, state: str, step: int) -> str:\n",
    "        \"\"\"Choose action using epsilon-greedy policy from the available actions for the current step.\"\"\"\n",
    "        available_actions = self.action_space.get(step)\n",
    "        \n",
    "        # Exploration: choose a random action\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.choice(available_actions)\n",
    "        \n",
    "        # Exploitation: choose the best-known action\n",
    "        q_values_for_state = self.q_table[state]\n",
    "        \n",
    "        # Filter Q-values to only include actions available at this step\n",
    "        available_q_values = {action: q_values_for_state[action] for action in available_actions}\n",
    "        \n",
    "        if not available_q_values or all(v == 0 for v in available_q_values.values()):\n",
    "            # If no q-values learned yet for this state, choose randomly\n",
    "            return random.choice(available_actions)\n",
    "        \n",
    "        return max(available_q_values, key=available_q_values.get)\n",
    "\n",
    "    def update_q_value(self, state: str, action: str, reward: float, next_state: str, next_step: int):\n",
    "        \"\"\"\n",
    "        Update Q-value using the Bellman equation from the image.\n",
    "        Q(S, A) <- Q(S, A) + Œ± * [R + Œ≥ * max_a Q(S', a) - Q(S, A)]\n",
    "        \"\"\"\n",
    "        # 1. Get the old Q-value: Q(S, A)\n",
    "        current_q = self.q_table[state][action]\n",
    "\n",
    "        # 2. Find the maximum Q-value for the next state: max_a Q(S', a)\n",
    "        next_q_values = self.q_table[next_state]\n",
    "        available_next_actions = self.action_space.get(next_step, [])\n",
    "        \n",
    "        max_next_q = 0\n",
    "        if next_q_values and available_next_actions:\n",
    "            # Consider only actions available in the next step\n",
    "            relevant_next_q = [next_q_values[act] for act in available_next_actions]\n",
    "            if relevant_next_q:\n",
    "                max_next_q = max(relevant_next_q)\n",
    "        \n",
    "        # 3. Calculate the TD target: R + Œ≥ * max_a Q(S', a)\n",
    "        td_target = reward + self.discount_factor * max_next_q\n",
    "        \n",
    "        # 4. Calculate the TD error: td_target - Q(S, A)\n",
    "        td_error = td_target - current_q\n",
    "\n",
    "        # 5. Update the Q-value: Q(S, A) + Œ± * TD_error\n",
    "        new_q = current_q + self.learning_rate * td_error\n",
    "        self.q_table[state][action] = new_q\n",
    "        \n",
    "        # print(f\"  üß† Q-Update: s={state}, a={action}, r={reward:.1f} | OldQ:{current_q:.2f} -> NewQ:{new_q:.2f}\")\n",
    "\n",
    "    def save_model(self):\n",
    "        \"\"\"Save the Q-table and hyperparameters to a JSON file.\"\"\"\n",
    "        try:\n",
    "            # Convert defaultdict to regular dict for JSON serialization\n",
    "            q_table_dict = {}\n",
    "            for state, actions in self.q_table.items():\n",
    "                q_table_dict[state] = dict(actions)\n",
    "            \n",
    "            model_data = {\n",
    "                \"q_table\": q_table_dict,\n",
    "                \"learning_rate\": self.learning_rate,\n",
    "                \"discount_factor\": self.discount_factor,\n",
    "                \"epsilon\": self.epsilon,\n",
    "                \"action_space\": self.action_space\n",
    "            }\n",
    "            \n",
    "            with open(self.model_path, 'w') as f:\n",
    "                json.dump(model_data, f, indent=2)\n",
    "            \n",
    "            print(f\"üíæ Model saved successfully to {self.model_path}\")\n",
    "            print(f\"   - Q-table entries: {len(q_table_dict)}\")\n",
    "            print(f\"   - Total state-action pairs: {sum(len(actions) for actions in q_table_dict.values())}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error saving model: {str(e)}\")\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"Load the Q-table and hyperparameters from a JSON file.\"\"\"\n",
    "        if not os.path.exists(self.model_path):\n",
    "            print(f\"üìÅ No existing model found at {self.model_path}. Starting with empty Q-table.\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            with open(self.model_path, 'r') as f:\n",
    "                model_data = json.load(f)\n",
    "            \n",
    "            # Restore Q-table\n",
    "            self.q_table = defaultdict(lambda: defaultdict(float))\n",
    "            for state, actions in model_data[\"q_table\"].items():\n",
    "                for action, value in actions.items():\n",
    "                    self.q_table[state][action] = value\n",
    "            \n",
    "            # Restore hyperparameters (optional, in case they were saved)\n",
    "            if \"learning_rate\" in model_data:\n",
    "                self.learning_rate = model_data[\"learning_rate\"]\n",
    "            if \"discount_factor\" in model_data:\n",
    "                self.discount_factor = model_data[\"discount_factor\"]\n",
    "            if \"epsilon\" in model_data:\n",
    "                self.epsilon = model_data[\"epsilon\"]\n",
    "            \n",
    "            print(f\"üìÇ Model loaded successfully from {self.model_path}\")\n",
    "            print(f\"   - Q-table entries: {len(model_data['q_table'])}\")\n",
    "            print(f\"   - Total state-action pairs: {sum(len(actions) for actions in model_data['q_table'].values())}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading model: {str(e)}\")\n",
    "            print(\"   Starting with empty Q-table.\")\n",
    "\n",
    "    def get_q_table_stats(self) -> Dict[str, any]:\n",
    "        \"\"\"Get statistics about the current Q-table.\"\"\"\n",
    "        total_states = len(self.q_table)\n",
    "        total_actions = sum(len(actions) for actions in self.q_table.values())\n",
    "        \n",
    "        # Calculate average Q-values per step\n",
    "        step_stats = {}\n",
    "        for state, actions in self.q_table.items():\n",
    "            if \"_step\" in state:\n",
    "                step_num = state.split(\"_step\")[1]\n",
    "                if step_num not in step_stats:\n",
    "                    step_stats[step_num] = {\"count\": 0, \"avg_q\": 0}\n",
    "                step_stats[step_num][\"count\"] += len(actions)\n",
    "                step_stats[step_num][\"avg_q\"] += sum(actions.values())\n",
    "        \n",
    "        for step in step_stats:\n",
    "            if step_stats[step][\"count\"] > 0:\n",
    "                step_stats[step][\"avg_q\"] /= step_stats[step][\"count\"]\n",
    "        \n",
    "        return {\n",
    "            \"total_states\": total_states,\n",
    "            \"total_actions\": total_actions,\n",
    "            \"step_stats\": step_stats\n",
    "        }\n",
    "\n",
    "class GeminiMathSolver:\n",
    "    def __init__(self, learner_model_name=\"gemini-1.5-flash-8b\", judge_model_name=\"gemini-2.5-pro\", model_path=\"qlearning_model.json\"):\n",
    "        self.agent = QLearningAgent(model_path=model_path)\n",
    "        self.max_steps = 5\n",
    "        self.max_retries_per_step = 3 # Allow the learner to try again if it makes a mistake\n",
    "        self.api_configured = False\n",
    "        self.model_path = model_path\n",
    "        \n",
    "        try:\n",
    "            self.learner_model = genai.GenerativeModel(learner_model_name)\n",
    "            self.judge_model = genai.GenerativeModel(judge_model_name)\n",
    "            self.api_configured = True\n",
    "            print(\"‚úÖ Gemini API configured successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Gemini API not configured. Running in MOCK mode. Error: {str(e)}\")\n",
    "    \n",
    "    def get_learner_response(self, problem: MathProblem, step: int, action: str, previous_steps: List[str], feedback: Optional[str] = None) -> str:\n",
    "        \"\"\"Generates a response from the learner model, incorporating feedback if provided.\"\"\"\n",
    "        if not self.api_configured:\n",
    "            return f\"[MOCK] Step {step}: Executing action '{action}' for problem type {problem.problem_type}.\"\n",
    "    \n",
    "        feedback_prompt = \"\"\n",
    "        if feedback:\n",
    "            feedback_prompt = f\"\"\"\n",
    "            Your previous attempt at this step was incorrect. Here is the feedback from the expert judge:\n",
    "            ---\n",
    "            {feedback}\n",
    "            ---\n",
    "            Please correct your mistake and provide a new, accurate response for this step.\n",
    "            \"\"\"\n",
    "    \n",
    "        # --- FIX IS HERE ---\n",
    "        # 1. Pre-format the 'previous_steps' string. Note the single backslash \\n is fine here.\n",
    "        if previous_steps:\n",
    "            previous_steps_str = \"\".join(f\"Step {i+1}: {s}\\n\" for i, s in enumerate(previous_steps))\n",
    "\n",
    "        else:\n",
    "            previous_steps_str = \"None\"\n",
    "        # --- END FIX ---\n",
    "    \n",
    "        step_instructions = {\n",
    "            1: \"Start by identifying the function/problem type and outlining the initial setup or first principle to apply.\",\n",
    "            2: \"Apply the main mathematical rule or technique (e.g., chain rule, integration by parts, matrix inversion).\",\n",
    "            3: \"Perform the necessary calculations and algebraic manipulations based on the previous step.\",\n",
    "            4: \"Simplify the resulting expression and check for any intermediate errors or edge cases.\",\n",
    "            5: \"State the complete, final answer clearly. This is your last step.\"\n",
    "        }\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "    You are an expert mathematician solving a calculus problem in a structured, 5-step process.\n",
    "    You are on step {step} of 5.\n",
    "    \n",
    "    Problem: {problem.problem}\n",
    "    \n",
    "    Previous Steps:\n",
    "    {previous_steps_str}\n",
    "    \n",
    "    Current Step Instructions ({step}/5): {step_instructions[step]}\n",
    "    Your high-level action for this step is: '{action}'.\n",
    "    \n",
    "    {feedback_prompt}\n",
    "    \n",
    "    Provide only the mathematical work for this current step.\n",
    "    {'This is the final step, you must provide the final answer.' if step == 5 else f'You have {5-step} steps remaining after this.'}\n",
    "    \"\"\"\n",
    "        response = self.learner_model.generate_content(prompt)\n",
    "        return response.text\n",
    "\n",
    "    def get_judge_evaluation(self, problem: MathProblem, step_content: str, step_number: int) -> Tuple[bool, float, str]:\n",
    "        \"\"\"Evaluates a step using the powerful judge model.\"\"\"\n",
    "        if not self.api_configured:\n",
    "            # Mock evaluation for testing without an API key\n",
    "            is_correct = random.random() > 0.4 # 60% chance of being correct\n",
    "            reward = (10 if is_correct else -5)\n",
    "            feedback = \"MOCK: This is a mock evaluation.\"\n",
    "            return is_correct, reward, feedback\n",
    "            \n",
    "        is_final_step = (step_number == self.max_steps)\n",
    "        \n",
    "        # --- CORRECTED JUDGE PROMPT ---\n",
    "        prompt = f\"\"\"\n",
    "    You are an expert mathematician and judge. Your task is to evaluate one step of a solution to a math problem.\n",
    "    The problem is: \"{problem.problem}\"\n",
    "    The expected final answer is: \"{problem.expected_answer}\"\n",
    "    \n",
    "    The current step being evaluated is Step {step_number}.\n",
    "    The student's submission for this step is:\n",
    "    ---\n",
    "    {step_content}\n",
    "    ---\n",
    "    \n",
    "    Based on the problem, the student's submission for this step, and the expected final answer, is this step correct?\n",
    "    - A step is CORRECT if it is mathematically sound and makes logical progress towards the final answer.\n",
    "    - A step is INCORRECT if it contains a mathematical error, a logical flaw, or is a step that doesn't lead to the correct solution.\n",
    "    \n",
    "    Start your response with the word \"CORRECT\" or \"INCORRECT\".\n",
    "    Then, provide a brief, one-sentence explanation for your decision.\n",
    "    \n",
    "    Example 1:\n",
    "    CORRECT: The application of the product rule is accurate.\n",
    "    \n",
    "    Example 2:\n",
    "    INCORRECT: The derivative of sin(x) is -cos(x), not cos(x) as written.\n",
    "    \n",
    "    Example 3:\n",
    "    INCORRECT: The calculation is correct, but this approach of integration by parts will not lead to the final answer.\n",
    "    \n",
    "    Now, evaluate the student's submission. The final answer should be: {problem.expected_answer}\n",
    "    \"\"\"\n",
    "        # --- END CORRECTED JUDGE PROMPT ---\n",
    "        \n",
    "        try:\n",
    "            response = self.judge_model.generate_content(prompt)\n",
    "            feedback_text = response.text.strip()\n",
    "            \n",
    "            is_correct = feedback_text.upper().startswith('CORRECT')\n",
    "            \n",
    "            # Define rewards\n",
    "            if is_correct:\n",
    "                reward = 15.0 if is_final_step else 5.0 + step_number\n",
    "            else:\n",
    "                reward = -20.0 if is_final_step else -10.0\n",
    "                \n",
    "            return is_correct, reward, feedback_text\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error during judge evaluation: {str(e)}\")\n",
    "            return False, -15.0, f\"Evaluation failed due to an API error: {e}\"\n",
    "\n",
    "    def solve_problem(self, problem: MathProblem) -> List[StepResult]:\n",
    "        \"\"\"Solves a problem using the Q-learning guided, 5-step process with retries.\"\"\"\n",
    "        print(f\"\\n\" + \"=\"*70)\n",
    "        print(f\"üßÆ Solving Problem: {problem.problem}\")\n",
    "        print(f\"üéØ Expected Answer: {problem.expected_answer}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        results = []\n",
    "        previous_steps_content = []\n",
    "\n",
    "        for step in range(1, self.max_steps + 1):\n",
    "            state = self.agent.get_state(problem, step)\n",
    "            feedback_for_retry = None\n",
    "            \n",
    "            for attempt in range(1, self.max_retries_per_step + 1):\n",
    "                # 1. Choose Action A from State S\n",
    "                action = self.agent.choose_action(state, step)\n",
    "\n",
    "                # 2. Take Action A, get Step Content\n",
    "                step_content = self.get_learner_response(problem, step, action, previous_steps_content, feedback_for_retry)\n",
    "                \n",
    "                # 3. Observe Reward R and Next State S'\n",
    "                is_correct, reward, judge_feedback = self.get_judge_evaluation(problem, step_content, step)\n",
    "                \n",
    "                status_icon = \"‚úÖ\" if is_correct else \"‚ùå\"\n",
    "                print(f\"Step {step}/{self.max_steps} (Attempt {attempt}) | Action: {action} | Result: {status_icon}\")\n",
    "                print(f\"  üí¨ Learner: {step_content.strip()}\")\n",
    "                print(f\"  üë®‚Äç‚öñÔ∏è Judge: {judge_feedback.strip()}\")\n",
    "                \n",
    "                if is_correct:\n",
    "                    # The step was correct, finalize and move to the next step\n",
    "                    result = StepResult(step, action, step_content, is_correct, reward, judge_feedback, attempt)\n",
    "                    results.append(result)\n",
    "                    previous_steps_content.append(step_content)\n",
    "                    \n",
    "                    # 4. Update Q-Table\n",
    "                    next_step = step + 1\n",
    "                    next_state = self.agent.get_state(problem, next_step) if next_step <= self.max_steps else \"terminal\"\n",
    "                    self.agent.update_q_value(state, action, reward, next_state, next_step)\n",
    "                    \n",
    "                    time.sleep(1) # API rate limiting\n",
    "                    break # Exit the retry loop\n",
    "                else:\n",
    "                    # The step was incorrect, prepare for another attempt\n",
    "                    feedback_for_retry = judge_feedback\n",
    "                    # Apply a penalty for the failed attempt and update Q-value to discourage this action\n",
    "                    self.agent.update_q_value(state, action, reward, state, step) # Update with penalty, next_state is current state\n",
    "                    \n",
    "                    if attempt == self.max_retries_per_step:\n",
    "                        # Max retries reached, accept the wrong answer and move on\n",
    "                        print(f\"  ‚ö†Ô∏è Max retries reached for step {step}. Accepting incorrect step.\")\n",
    "                        result = StepResult(step, action, step_content, is_correct, reward, judge_feedback, attempt)\n",
    "                        results.append(result)\n",
    "                        previous_steps_content.append(step_content)\n",
    "                        break # Exit the retry loop\n",
    "                    \n",
    "                    time.sleep(1) # API rate limiting\n",
    "\n",
    "        # Save the model after each problem\n",
    "        self.agent.save_model()\n",
    "\n",
    "        # Final Summary\n",
    "        total_reward = sum(r.reward for r in results)\n",
    "        correct_steps = sum(1 for r in results if r.is_correct)\n",
    "        print(\"\\n\" + \"-\"*30 + \" SUMMARY \" + \"-\"*30)\n",
    "        print(f\"üìä Final Result: {correct_steps}/{self.max_steps} steps correct.\")\n",
    "        print(f\"üèÜ Total Reward: {total_reward:.1f}\")\n",
    "        print(\"=\"*70)\n",
    "        return results\n",
    "\n",
    "    def print_model_stats(self):\n",
    "        \"\"\"Print statistics about the current Q-learning model.\"\"\"\n",
    "        stats = self.agent.get_q_table_stats()\n",
    "        print(\"\\n\" + \"=\"*30 + \" MODEL STATISTICS \" + \"=\"*30)\n",
    "        print(f\"üìä Total States: {stats['total_states']}\")\n",
    "        print(f\"üìä Total State-Action Pairs: {stats['total_actions']}\")\n",
    "        \n",
    "        if stats['step_stats']:\n",
    "            print(\"\\nüìà Step-wise Statistics:\")\n",
    "            for step, data in stats['step_stats'].items():\n",
    "                print(f\"  Step {step}: {data['count']} actions, avg Q-value: {data['avg_q']:.3f}\")\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "\n",
    "# --- Main Execution ---\n",
    "def create_hard_problems() -> List[MathProblem]:\n",
    "    \"\"\"Create a list of hard and very hard sample math problems for testing.\"\"\"\n",
    "    return [\n",
    "        MathProblem(\n",
    "            problem=\"Find the derivative of the Weierstrass function, defined as f(x) = Œ£ [from n=0 to ‚àû] a‚Åø * cos(b‚ÅøœÄx), for 0 < a < 1 and ab > 1 + (3/2)œÄ.\",\n",
    "            problem_type=\"derivative\",\n",
    "            difficulty=\"very_hard\",\n",
    "            expected_answer=\"The function is continuous everywhere but differentiable nowhere. Therefore, the derivative does not exist for any value of x.\"\n",
    "        ),\n",
    "        MathProblem(\n",
    "            problem=\"Consider f_n(x) = 2nx*e^(-nx¬≤) on [0, 1]. Evaluate lim[n‚Üí‚àû] ‚à´[0 to 1] f_n(x) dx and ‚à´[0 to 1] lim[n‚Üí‚àû] f_n(x) dx. Are they equal?\",\n",
    "            problem_type=\"real_analysis\",\n",
    "            difficulty=\"very_hard\",\n",
    "            expected_answer=\"They are not equal. The integral of the limit is ‚à´0 dx = 0. The limit of the integral is lim[n‚Üí‚àû] (1 - e‚Åª‚Åø) = 1. They differ because convergence is not uniform, so the limit and integral cannot be interchanged.\"\n",
    "        ),\n",
    "        MathProblem(\n",
    "            problem=\"Find the derivative of f(x) = x^2 + 3x + 2\",\n",
    "            problem_type=\"derivative\",\n",
    "            difficulty=\"easy\",\n",
    "            expected_answer=\"f'(x) = 2x + 3\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "\n",
    "def main():\n",
    "    # You can specify a custom model path if needed\n",
    "    model_path = \"math_qlearning_model.json\"\n",
    "    solver = GeminiMathSolver(model_path=model_path)\n",
    "    \n",
    "    if not solver.api_configured:\n",
    "        print(\"\\n--- RUNNING IN MOCK MODE. NO REAL LEARNING WILL OCCUR. ---\")\n",
    "        print(\"--- Please configure your Gemini API key to run properly. ---\")\n",
    "\n",
    "    # Print initial model statistics\n",
    "    solver.print_model_stats()\n",
    "\n",
    "    problems = create_hard_problems()\n",
    "    for prob in problems:\n",
    "        solver.solve_problem(prob)\n",
    "\n",
    "    # Print final model statistics\n",
    "    solver.print_model_stats()\n",
    "\n",
    "    print(\"\\n\\n\" + \"=\"*30 + \" FINAL Q-TABLE STATE \" + \"=\"*30)\n",
    "    # Print a few learned Q-values to show it's working\n",
    "    if solver.agent.q_table:\n",
    "        for i, (state, actions) in enumerate(solver.agent.q_table.items()):\n",
    "            if i >= 5: break\n",
    "            print(f\"State: {state}\")\n",
    "            for action, value in actions.items():\n",
    "                print(f\"  - Action: {action}, Q-Value: {value:.3f}\")\n",
    "    else:\n",
    "        print(\"Q-Table is empty (likely ran in mock mode).\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
